import { NextResponse } from 'next/server';
import { VertexAI } from '@google-cloud/vertexai'; // SDK da Vertex AI (para Inpainting/Imagen)
import {
  GoogleGenerativeAI, // SDK do Gemini (para An√°lise de Vis√£o)
  Part,
} from '@google/generative-ai';

// --- Configura√ß√£o dos Clientes de IA ---
// NOTA: Isso requer vari√°veis de ambiente em .env.local:
// GOOGLE_CLOUD_PROJECT = "seu-projeto-gcloud"
// GOOGLE_CLOUD_LOCATION = "us-central1"
// GEMINI_API_KEY = "sua-chave-api-gemini-aqui"
// ----------------------------------------------------

// 1. Cliente Vertex AI (para Inpainting/Imagen)
// Inicializa√ß√£o apenas se as vari√°veis estiverem configuradas
let imagenModel: ReturnType<VertexAI['preview']['getGenerativeModel']> | null = null;

if (process.env.GOOGLE_CLOUD_PROJECT && process.env.GOOGLE_CLOUD_LOCATION) {
  const vertexAI = new VertexAI({
    project: process.env.GOOGLE_CLOUD_PROJECT,
    location: process.env.GOOGLE_CLOUD_LOCATION,
  });

  imagenModel = vertexAI.preview.getGenerativeModel({
    model: 'imagegeneration@0.0.6', // Modelo de edi√ß√£o/gera√ß√£o de imagem (Imagen)
  });
}

// 2. Cliente Gemini (para An√°lise de Vis√£o)
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '');

// --- Helper para converter Arquivo (File) para a API do Google ---
async function fileToGenerativePart(file: File): Promise<Part> {
  const base64EncodedData = Buffer.from(await file.arrayBuffer()).toString(
    'base64',
  );
  return {
    inlineData: { data: base64EncodedData, mimeType: file.type },
  };
}

// --- A Rota da API (POST) ---
export async function POST(request: Request) {
  try {
    // 1. Ler os 3 arquivos do FormData (Contrato 6.2)
    const formData = await request.formData();
    const friendImageFile = formData.get('friendImage') as File | null;
    const baseImageFile = formData.get('baseImage') as File | null;
    const maskImageFile = formData.get('maskImage') as File | null;

    if (!friendImageFile || !baseImageFile || !maskImageFile) {
      return NextResponse.json(
        { error: 'Arquivos ausentes. (friendImage, baseImage, maskImage s√£o obrigat√≥rios)' },
        { status: 400 },
      );
    }

    // --- ETAPA DE IA 1: An√°lise de Vis√£o (Gemini) ---
    // (Descrever a friendImage para criar o prompt de inpainting)

    console.log('Iniciando Etapa 1: An√°lise de Vis√£o (Gemini)');
    const friendImagePart = await fileToGenerativePart(friendImageFile);
    const visionPrompt =
      'Descreva esta pessoa em detalhes objetivos para uma IA de gera√ß√£o de imagem. Foque em: sexo, idade aproximada, etnia, cor e estilo do cabelo, pelos faciais (barba/bigode), √≥culos e quaisquer caracter√≠sticas marcantes. Seja conciso e direto. Responda apenas com a descri√ß√£o.';

    // Tentar diferentes modelos em ordem de prefer√™ncia
    // PRIORIDADE: gemini-pro-vision (modelo especializado em vis√£o)
    const modelsToTry = [
      'gemini-pro-vision',     // Modelo especializado em vis√£o (recomendado)
      'gemini-2.0-flash-exp',  // Modelo experimental mais recente
      'gemini-1.5-flash-002',  // Vers√£o espec√≠fica do Flash
      'gemini-1.5-pro-002',    // Vers√£o espec√≠fica do Pro
      'gemini-1.5-flash',      // Flash sem vers√£o
      'gemini-1.5-pro',        // Pro sem vers√£o
    ];
    
    let visionResult;
    let textPrompt = '';
    let lastError: Error | null = null;

    console.log('üîç Iniciando tentativas com modelos Gemini...');
    for (const modelName of modelsToTry) {
      try {
        console.log(`üîÑ Tentando modelo: ${modelName}`);
        const model = genAI.getGenerativeModel({ model: modelName });
        visionResult = await model.generateContent([
          visionPrompt,
          friendImagePart,
        ]);
        textPrompt = visionResult.response.text();
        if (textPrompt && textPrompt.trim() !== '') {
          console.log(`‚úÖ Modelo ${modelName} funcionou com sucesso!`);
          break;
        }
      } catch (error) {
        lastError = error instanceof Error ? error : new Error(String(error));
        console.log(`‚ùå Modelo ${modelName} falhou: ${lastError.message}`);
        continue;
      }
    }

    if (!textPrompt || textPrompt.trim() === '') {
      return NextResponse.json(
        { error: `N√£o foi poss√≠vel analisar a imagem do amigo. √öltimo erro: ${lastError?.message || 'Nenhum modelo dispon√≠vel'}` },
        { status: 500 },
      );
    }

    // Este √© o prompt que ser√° usado para "pintar" o amigo na cena
    const finalInpaintingPrompt = `FOTO: ${textPrompt}, em um cen√°rio com um pol√≠tico, fotorrealista.`;
    console.log('Etapa 1 Conclu√≠da. Prompt Gerado:', finalInpaintingPrompt);


    // --- ETAPA DE IA 2: Inpainting (Vertex AI / Imagen) ---
    // (Usar a descri√ß√£o gerada para preencher a m√°scara)

    // Verificar se VertexAI est√° configurado
    if (!imagenModel) {
      return NextResponse.json(
        { error: 'Vertex AI n√£o est√° configurado. Configure GOOGLE_CLOUD_PROJECT e GOOGLE_CLOUD_LOCATION nas vari√°veis de ambiente.' },
        { status: 500 },
      );
    }

    console.log('Iniciando Etapa 2: Inpainting (Vertex AI)');
    const baseImagePart = await fileToGenerativePart(baseImageFile);
    const maskImagePart = await fileToGenerativePart(maskImageFile);

    const inpaintingRequest = {
      prompt: finalInpaintingPrompt,
      image: baseImagePart, // Imagem base (pol√≠tico)
      mask: { image: maskImagePart }, // M√°scara (buraco)
      generationConfig: {
        count: 1,
        guidanceScale: 12, // For√ßa a IA a seguir o prompt com mais rigor
      },
    };

    // @ts-expect-error - O SDK do @google-cloud/vertexai pode ter tipos complexos
    const inpaintingResponse = await imagenModel.editImage(inpaintingRequest);

    // Acessar a resposta de forma segura
    let imageBase64: string | undefined;
    const response = inpaintingResponse as unknown;
    if (Array.isArray(response) && response.length > 0) {
      const firstItem = response[0] as Record<string, unknown>;
      imageBase64 = (firstItem?.imageBytes as string) || (firstItem?.bytes as string) || (firstItem?.data as string);
    } else if (response && typeof response === 'object') {
      const responseObj = response as Record<string, unknown>;
      imageBase64 = (responseObj.imageBytes as string) || (responseObj.bytes as string) || (responseObj.data as string);
    }
    
    if (!imageBase64) {
      return NextResponse.json(
        { error: 'A IA de edi√ß√£o n√£o retornou uma imagem.' },
        { status: 500 },
      );
    }

    // --- Resposta (Sucesso - Contrato 6.2) ---
    console.log('Etapa 2 Conclu√≠da. Enviando imagem gerada.');

    // Decodifica o base64 e retorna os bytes puros da imagem
    const imageBytes = Buffer.from(imageBase64, 'base64');
    
    // Retorna a imagem PNG pura, conforme Se√ß√£o 6.2 do PRD
    return new NextResponse(imageBytes, {
      status: 200,
      headers: {
        'Content-Type': 'image/png',
      },
    });

  } catch (error) {
    console.error('Erro grave na API /api/generate:', error);
    const errorMessage = error instanceof Error ? error.message : 'Erro interno do servidor.';
    return NextResponse.json(
      { error: errorMessage },
      { status: 500 },
    );
  }
}
